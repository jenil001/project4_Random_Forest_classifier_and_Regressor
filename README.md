# Random Forest Project 🚀  

This repository contains implementations of **Random Forest Classification** and **Random Forest Regression** using Python and Jupyter Notebook. The projects showcase how Random Forest, one of the most popular ensemble learning techniques, can be applied to real-world datasets for predictive modeling.  

## 📂 Project Files  

- **`Random_Forest_Classification.ipynb`**  
  - Demonstrates Random Forest Classification on the **Travel dataset (`Travel.csv`)**.  
  - Predicts outcomes based on user travel-related data.  

- **`Random_Forest_Regression_Implementation.ipynb`**  
  - Demonstrates Random Forest Regression using the **CarDekho dataset (`cardekho_imputated.csv`)**.  
  - Predicts car prices based on features such as brand, year, fuel type, etc.  

- **Datasets:**  
  - `Travel.csv` → Dataset for classification tasks.  Link: https://www.kaggle.com/datasets/susant4learning/holiday-package-purchase-prediction
  - `cardekho_imputated.csv` → Dataset for regression tasks. The Dataset is collected from scrapping from cardheko webiste

## 🛠️ Tech Stack  

- **Language:** Python 🐍  
- **Libraries Used:**  
  - NumPy  
  - Pandas  
  - Matplotlib / Seaborn (for visualization)  
  - scikit-learn (for Random Forest models)  
  - Jupyter Notebook  

## 🎯 Key Objectives  

1. Implement Random Forest Classification and Regression models.  
2. Understand feature importance and decision-making of Random Forest.  
3. Visualize results and compare model performance.  
4. Work with real-world datasets for practical insights.  

## 📊 Results  

- **Classification:** Achieved accurate predictions on travel dataset with well-balanced precision and recall.  
- **Regression:** Successfully predicted car prices with minimal error, showing Random Forest’s robustness in handling nonlinear relationships.  

## 📸 Sample Outputs  

- Confusion Matrix and Accuracy scores (Classification)  
- Feature Importance Graphs  
- Predicted vs Actual Price plots (Regression)  

## 📌 Future Work  

- Hyperparameter tuning for better accuracy.  
- Try Gradient Boosting and XGBoost for comparison.  
- Deploy models using Flask/Streamlit.  

